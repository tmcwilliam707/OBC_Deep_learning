{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for Power Usage Prediction\n",
    "---\n",
    "This notebook contains code to train a simple, 2-layer neural net to predict a regression target: `Global_active_power`. This is to approach the problem of household power consumption, in accordance with my stated goal and hypothesis:\n",
    "> **Predictive goal**: Predict future active power that a household will need on an hourly basis (e.g, at 9am, 10am, etc.) with high accuracy. The best predictions will avoid underestimating the active power.¬†\n",
    "\n",
    ">**Hypothesis**: I think power meter readings and _past_ hourly usage will be great predictors for an ML model. \n",
    "\n",
    "In previous notebooks, I formatted train and test data in prep for training an ML model, and trained a baseline linear regression model:\n",
    "> Baseline RMSE: ~0.34.\n",
    "\n",
    "üìçIn this notebook, I will attend to the same measure of error, and see if I can improve upon the baseline in terms of overall RMSE as well as in avoiding cases of under-estimation.\n",
    "\n",
    "### NN Model Creation\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Load the data\n",
    "2. Create train/test dataloaders\n",
    "3. Define a neural network\n",
    "4. Train the model\n",
    "5. Evaluate the performance of our trained model on a test dataset\n",
    "6. Further investigate patterns in errors\n",
    "7. UX Considerations\n",
    "\n",
    "These are almost the same steps as when I developed a baseline solution. \n",
    "\n",
    "One additional step, of note, is step 3: **Define a neural network**\n",
    "\n",
    "In developing an NN-based solution, you'll typically have to define the architecture of that neural network, rather than relying on a default algorithm structure like linear regression. \n",
    "\n",
    "Before we begin, we have to import the necessary libraries for working with data and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# import data libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Data\n",
    "\n",
    "\n",
    "This cell defines a custom Dataset class that will allow us to read in a specifically-formatted csv file of power usage data, and convert that data into Tensors for PyTorch to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import PowerConsumptionDataset\n",
    "\n",
    "# creating train and test datasets using the PowerConsumptionDataset class\n",
    "train_path = 'data/train_hourly.pkl'\n",
    "train_dataset = PowerConsumptionDataset(pkl_file=train_path)\n",
    "\n",
    "test_path = 'data/test_hourly.pkl'\n",
    "test_dataset = PowerConsumptionDataset(pkl_file=test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(tensor([  1.0728,   0.9341,  17.0000, 234.6439,   0.0000,   0.5278,  16.8611]), tensor([4.2229]))\n",
      "\n",
      "(tensor([  1.3521,   1.0581,  18.0000, 234.5802,   0.0000,   6.7167,  16.8667]), tensor([3.6322]))\n",
      "\n",
      "(tensor([  1.7886,   1.1519,  19.0000, 233.2325,   0.0000,   1.4333,  16.6833]), tensor([3.4002]))\n"
     ]
    }
   ],
   "source": [
    "# print out a few (3) samples to see that it looks right\n",
    "# I should have 7 input features and 1 target\n",
    "\n",
    "for i in range(3):\n",
    "    sample = train_dataset[i]\n",
    "    print()\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Creating DataLoaders for Train/Test Datasets\n",
    "\n",
    "DataLoaders allow us to do things like batch data (for batch learning), shuffle data, etc.‚Äîthey are the standard way to iterate through data for training a PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples per batch\n",
    "batch_size = 64\n",
    "\n",
    "# train and test loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Define the Neural Network Architecture\n",
    "\n",
    "The architecture will be responsible for transforming input features into a single target value. \n",
    "\n",
    "> This particular example defines a 2-layer NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing NN modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# a simple 2 layer (input-hidden-output) NN\n",
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    ## Defines the layers of an NN\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        '''Defines layers of a neural network.\n",
    "           :param input_dim: Number of input features\n",
    "           :param hidden_dim: Size of hidden layer(s)\n",
    "           :param output_dim: Number of outputs\n",
    "         '''\n",
    "        super(SimpleNet, self).__init__()\n",
    "                \n",
    "        # defining linear layers that go input > hidden > output\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    ## Defines the feedforward behavior of the network\n",
    "    def forward(self, x):\n",
    "        '''Feedforward behavior of the net.\n",
    "           :param x: A batch of input features\n",
    "           :return: A batch of output values; predictions\n",
    "         '''\n",
    "        out = F.relu(self.fc1(x)) # ReLU activation fn applied to output of hidden layer\n",
    "        out = self.fc2(out) # final output, no activation fn needed \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=7, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating the simple NN with specified dimensions\n",
    "\n",
    "input_dim = 7 # input feats\n",
    "output_dim = 1 # one target value\n",
    "hidden_dim = 10 # nodes in hidden layer\n",
    "\n",
    "\n",
    "model = SimpleNet(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# print model layers (from init fn)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimization strategy\n",
    "\n",
    "The loss function defines what a network tries to minimize in terms of comparing actual versus predicted values. In classification tasks, it is common to use a cross entropy loss and in regression tasks, such as this one, you'll commonly see mean squared error or root mean squared error (RMSE). You can also create custom loss functions depending on what you want to optimize for!\n",
    "\n",
    "The optimizer defines how a neural network updates or learns as a result of trying to minimize the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy for classification, mse for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Train loop + saving a model\n",
    "\n",
    "In the `helpers.py` file I include code for a training loop that does the following:\n",
    "* Iterate through the training data in batches provided by the `train_loader` \n",
    "* Calculate the loss (RMSE) and backpropagate to find the source of this error\n",
    "* Update the weights of this NN to decrease the loss\n",
    "* After a specified number of epochs, save the final, trained model\n",
    "\n",
    "\n",
    "üìç **EXPERIMENTAL NOTE:** I'd like to add validation data to implement early-stopping and avoid overfitting even more. For now, I am eye-balling an appropriate number of epochs to run instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.0393941646499885\n",
      "Epoch: 2, Loss: 0.6835263245325867\n",
      "Epoch: 3, Loss: 0.6374956142130516\n",
      "Epoch: 4, Loss: 0.5903895092453603\n",
      "Epoch: 5, Loss: 0.5523993382565409\n",
      "Epoch: 6, Loss: 0.5183460384750251\n",
      "Epoch: 7, Loss: 0.4992046398724869\n",
      "Epoch: 8, Loss: 0.4758248953796405\n",
      "Epoch: 9, Loss: 0.4617599566563142\n",
      "Epoch: 10, Loss: 0.45188950731171124\n",
      "Epoch: 11, Loss: 0.44272165272018604\n",
      "Epoch: 12, Loss: 0.4378582664923988\n",
      "Epoch: 13, Loss: 0.4333353827146889\n",
      "Epoch: 14, Loss: 0.42942123668942805\n",
      "Epoch: 15, Loss: 0.4256879380709833\n",
      "Saving the model as model_10hdn_15ep.pth\n"
     ]
    }
   ],
   "source": [
    "from helpers import train\n",
    "\n",
    "# I've created this local directory to save trained models\n",
    "MODEL_DIR = 'saved_models/'\n",
    "model_name = 'model_10hdn_15ep.pth'\n",
    "\n",
    "# define number of epochs - times you iterate through the entire training dataset\n",
    "n_epochs = 15\n",
    "\n",
    "# call train function with all params\n",
    "model = train(model, train_loader, n_epochs, optimizer, criterion, model_name, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Test the Trained Network\n",
    "\n",
    "Finally, I test my trained model on **test data** which it has NOT seen during training, and evaluate its performance in terms of RMSE. This calculation is completed by another function in `helpers.py`.\n",
    "\n",
    "Testing on unseen data is a good way to check that our model generalizes well, and, in this case, if it can generalize to future data (2010 vs 2006-2009). \n",
    "\n",
    "It may also be useful to be granular in this analysis and take a look at the distribution of errors that the model tends to make by comparing actual versus predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.318717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from helpers import test_eval\n",
    "\n",
    "test_rmse = test_eval(model, test_loader, criterion)\n",
    "\n",
    "print('Test RMSE: {:.6f}\\n'.format(test_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple NN RMSE** üìù\n",
    "\n",
    "This looks like a _slight_ improvement on the baseline model, which is promising!\n",
    "> From a baseline of around 0.34 RMSE to a simple NN value of about 0.32 RMSE.\n",
    "\n",
    "Simple NNs should produce at least comparable results to a good baseline. And, of course, I will haev to look at the distribution of errors to see if this does better in the way we care about for this use case: less likely to under-estimate power usage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Further Comparing Predictions vs Targets\n",
    "\n",
    "üìù The RMSE looks slightly improved when compared to the linear regression model trained as a baseline, which is promising! \n",
    "\n",
    "Next, I compare target versus predicted values in the same way that I would do for a baseline‚Äîlooking at the distribution of errors and especially attending to under-estimations. For this, I am using turicreate's `show()` but other summary stats or viz tools will work well too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual and predicted values (from model)\n",
    "actual = test_dataset[:][1]\n",
    "preds = model(test_dataset[:][0])\n",
    "\n",
    "# get diffs and turn into numpy array\n",
    "diffs = actual - preds\n",
    "diffs_np = diffs.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "\n",
    "# convert np array to SFrame for tc distribution viz\n",
    "diffs_tc = tc.SFrame(diffs_np)\n",
    "\n",
    "# uncomment\n",
    "#diffs_tc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Step 7: Further UX Considerations üìù \n",
    "\n",
    "At Apple, we are always thinking about the nuances of the user experience for different populations. This section represent answers to a set of questions that ask us to consider inclusive design practices, such as:\n",
    "\n",
    "* **Failure cases**: What might go wrong, and how does the likelihood of failures vary across users?\n",
    "* **Delight**: What potential impact of the OBC feature are you most excited about?\n",
    "\n",
    "For any model you are thinking of putting into production or sharing with a larger team, you should critically consider the different tradeoffs and impacts such a trained model could have on different users. \n",
    "\n",
    "### Potential failure cases: \n",
    "\n",
    "* **User experience and fairness**: I would like to test this model on different locales around the world to see if performance is fair/even across different geographic locations. \n",
    "    * Taking averages and training on limited data will bias this model towards the locale that is best represented in this data and in these averages, which in this case is one locale: a household near Paris, France (from the dataset description)\n",
    "    * Further, do different locales have the same style and format of sub-meter readings or do they have more/less/different input information? I could imagine that if different sub-meters are attached to different rooms in a house or one house has way more or way fewer appliances, or even if the meters record information in a different format‚Äîdifferent models may need to be created depending on the available information.\n",
    "\n",
    "* **Reducing costly errors**: This model still under-estimates occasionally, which is a costly error in terms of being harmful for how power companies can prepare to deliver power, and so we may want to tune or establish some rule-based cutoffs that ensure that under-estimations do not occur. \n",
    "\n",
    "* **Extreme conditions**: Such a model will likely only work in standard (predictable) conditions; we need a failsafe for, say, blackouts, particularly cold or hot weather where people may be over-using A/C, etc.‚ÄîI should partner with power companies and users to better understand these failure risks. \n",
    "\n",
    "### Potential for delight: \n",
    "\n",
    "* **Environmental impact**: Ideally, these predictions can be used to efficiently allocate power resources so that none go to waste; low or zero-waste has positive environmental and financial impacts.\n",
    "\n",
    "* **Open question**: How should these predictions be surfaced to power companies so they can make the most informed predictions? Perhaps it's important that they also know more about how these predictions are made or what the confidence of certain predictions are. I should discuss with power companies to better understand their decision-making processes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
